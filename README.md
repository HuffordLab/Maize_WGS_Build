# Maize_WGS_Build
Code and Data to include in WGS Build

Start with the workflow documented on [Bioinformatic Workbook GATK DNAseq Best Practices](https://bioinformaticsworkbook.org/dataAnalysis/VariantCalling/gatk-dnaseq-best-practices-workflow.html#gsc.tab=0)

> ### Running the pipeline
>
> If on a local laptop with nextflow installed:
> 
> ```
> nextflow run HuffordLab/Maize_WGS_Build
> ```
> 
> If on HPCC Condo:
> 
> ```
> module load gcc/7.3.0-xegsmw4 nextflow
> nextflow run HuffordLab/Maize_WGS_Build -profile condo
> ```

### Edit: LFS test data

Because test data requires `git lfs`, the above commands will not pull the `test-data`. Therefore first `git lfs clone` the large data files and then run the main nextflow script (`main.nf`).

For running on HPCC Condo:

```
git lfs clone https://github.com/HuffordLab/Maize_WGS_Build.git
cd Maize_WGS_Build

module load gcc/7.3.0-xegsmw4 nextflow
nextflow run main.nf -profile condo
```

<details><summary>See example HPCC Condo running output </summary>

In this case there are 101 slurm jobs on the queue so far. The process `fastqc` has a total of 258 jobs to submit (one for each `test-data` fastq file).

```
nextflow run main.nf -profile condo
#> N E X T F L O W  ~  version 20.07.1
#> Launching `main.nf` [boring_carson] - revision: 99983aad6a
#> executor >  slurm (101)
#> [0f/70feab] process > fastqc (null)         [  0%] 1 of 258
#> [f4/0b666a] process > gatk0_index_help      [  0%] 0 of 1
#> [ef/d2fbd1] process > gatk0_index (1)       [  0%] 0 of 1
#> [2d/c71570] process > gatk2_preprocess_help [100%] 1 of 1 ✔
#> [57/4481cd] process > gatk3_cmdsgen_help    [100%] 1 of 1 ✔
#> [cf/a201a6] process > gatk4_filter_help     [100%] 1 of 1 ✔
#> /work/GIF/jenchang/_wrkspc/_testremote/Maize_WGS_Build/test-data/ref/b73_chr1_150000001-151000000.fasta
#> /work/GIF/jenchang/_wrkspc/_testremote/Maize_WGS_Build/test-data/fastq/1721-5_S1_L004_R1_001.fastq.gz
#> /work/GIF/jenchang/_wrkspc/_testremote/Maize_WGS_Build/test-data/fastq/CML333_S0_L001_R2_001.fastq.gz
#> /work/GIF/jenchang/_wrkspc/_testremote/Maize_WGS_Build/test-data/fastq/1508-1_S1_L004_R2_001.fa
```
</details>

All output is in a `results` folder.

<details><summary>See explaination of <b>results</b> folder</summary>
  
  ```
  results/
    |_ report.html       # detailed breakdown of which processes where run on what input
    |_ timeline.html     # gantt chart-like timeline of each process and how long it ran
    |
    |_ fastqc/           # Contains the html files generated by fastqc quality check
    |_ 0_index/          # Contains the genome index files generated by gatk0
    |_ ....
  ```
  
</details>


### Test dataset

A simple test dataset is available (here)[/test-data]. This dataset contains a small genome (portion of chr1, B73v5), and Illumina short reads for 26 NAM lines (including B73) and B73Ab10 line (27 lines total).
Only the reads that map to the region of the v5 genome is included, so that this can be tested quickly.
There are examples of multiple files belonging to same NAM line as well as single file per NAM line to make sure both conditions works correctly.
The end VCF file should have exactly 27 individuals (lines) in them.

* Test DataSet is on ISU Box -- [https://iastate.app.box.com/v/gatk-test-data](https://iastate.app.box.com/v/gatk-test-data)

### Container 

Tools required for the workflow are included in the container

#### To pull the image

```
singularity pull --name gatk.sif shub://aseetharam/gatk:latest
```

#### To use the image

```
singularity exec gatk.sif samtools
singularity exec gatk.sif bwa
singularity exec gatk.sif datamash
singularity exec gatk.sif java -jar $GATKHOME/$GATK
singularity exec gatk.sif java -jar $PICARDHOME/picard.jar
```

